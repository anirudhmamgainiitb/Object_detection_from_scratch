{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Saved to outputs/result3.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.detector import Detector\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "IMG_PATH = \"/Users/anirudhmamgain/Desktop/Object_detection_from_scratch/Dataset/train/images/IMG_8471_jpg.rf.ae5a71d679103fd7cba244719b0e3157.jpg\"\n",
    "CHECKPOINT = \"/Users/anirudhmamgain/Desktop/Object_detection_from_scratch/checkpoints/new_last_model.pth\"\n",
    "\n",
    "IMG_SIZE = 416\n",
    "GRID_SIZE = 52\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "OBJ_THRESH = 0.9\n",
    "SCORE_THRESH = 0.2\n",
    "NMS_IOU_THRESH = 0.2\n",
    "MAX_DETECTIONS = 10\n",
    "\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"fish\", \"jellyfish\", \"penguin\",\n",
    "    \"puffin\", \"shark\", \"starfish\", \"stingray\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ---------------- NMS ----------------\n",
    "def nms(boxes, scores, iou_thresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "    scores = torch.tensor(scores, dtype=torch.float32)\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    order = scores.argsort(descending=True)\n",
    "\n",
    "    keep = []\n",
    "\n",
    "    while order.numel() > 0:\n",
    "        i = order[0].item()\n",
    "        keep.append(i)\n",
    "\n",
    "        if order.numel() == 1:\n",
    "            break\n",
    "\n",
    "        xx1 = torch.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = torch.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = torch.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = torch.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        inter = (xx2 - xx1).clamp(0) * (yy2 - yy1).clamp(0)\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)\n",
    "\n",
    "        order = order[1:][iou < iou_thresh]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "# ---------------- LOAD MODEL ----------------\n",
    "model = Detector(num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(CHECKPOINT, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- LOAD IMAGE ----------------\n",
    "img = cv2.imread(IMG_PATH)\n",
    "orig_h, orig_w = img.shape[:2]\n",
    "\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "img_tensor = torch.from_numpy(img_resized).float() / 255.0\n",
    "img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "# ---------------- INFERENCE ----------------\n",
    "with torch.no_grad():\n",
    "    preds = model(img_tensor)\n",
    "\n",
    "preds = preds.permute(0, 2, 3, 1)[0]  # [52, 52, 5 + C]\n",
    "\n",
    "boxes = []\n",
    "scores = []\n",
    "labels = []\n",
    "\n",
    "# ---------------- DECODE ----------------\n",
    "for gy in range(GRID_SIZE):\n",
    "    for gx in range(GRID_SIZE):\n",
    "        obj = torch.sigmoid(preds[gy, gx, 4]).item()\n",
    "        if obj < OBJ_THRESH:\n",
    "            continue\n",
    "\n",
    "        cls_probs = torch.sigmoid(preds[gy, gx, 5:])\n",
    "        cls_id = torch.argmax(cls_probs).item()\n",
    "        cls_conf = cls_probs[cls_id].item()\n",
    "\n",
    "        score = obj * cls_conf\n",
    "        if score < SCORE_THRESH:\n",
    "            continue\n",
    "\n",
    "        cx, cy, w, h = torch.sigmoid(preds[gy, gx, :4]).cpu().numpy()\n",
    "\n",
    "        cx = cx * orig_w\n",
    "        cy = cy * orig_h\n",
    "        w  = w  * orig_w\n",
    "        h  = h  * orig_h\n",
    "\n",
    "        MAX_BOX_RATIO = 0.4\n",
    "        w = min(w, MAX_BOX_RATIO * orig_w)\n",
    "        h = min(h, MAX_BOX_RATIO * orig_h)\n",
    "\n",
    "        x1 = int(cx - w / 2)\n",
    "        y1 = int(cy - h / 2)\n",
    "        x2 = int(cx + w / 2)\n",
    "        y2 = int(cy + h / 2)\n",
    "\n",
    "\n",
    "\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        scores.append(score)\n",
    "        labels.append(cls_id)\n",
    "\n",
    "# ---------------- PER-CLASS NMS ----------------\n",
    "final_indices = []\n",
    "\n",
    "for cls in range(NUM_CLASSES):\n",
    "    cls_boxes = []\n",
    "    cls_scores = []\n",
    "    cls_map = []\n",
    "\n",
    "    for i, lbl in enumerate(labels):\n",
    "        if lbl == cls:\n",
    "            cls_boxes.append(boxes[i])\n",
    "            cls_scores.append(scores[i])\n",
    "            cls_map.append(i)\n",
    "\n",
    "    keep = nms(cls_boxes, cls_scores, NMS_IOU_THRESH)\n",
    "\n",
    "    for k in keep:\n",
    "        final_indices.append(cls_map[k])\n",
    "\n",
    "# ---------------- LIMIT MAX DETECTIONS ----------------\n",
    "final_indices = sorted(\n",
    "    final_indices,\n",
    "    key=lambda i: scores[i],\n",
    "    reverse=True\n",
    ")[:MAX_DETECTIONS]\n",
    "\n",
    "# ---------------- DRAW ----------------\n",
    "for i in final_indices:\n",
    "    x1, y1, x2, y2 = boxes[i]\n",
    "    cls_id = labels[i]\n",
    "    score = scores[i]\n",
    "\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    text = f\"{CLASS_NAMES[cls_id]} {score:.2f}\"\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text,\n",
    "        (x1, max(y1 - 5, 10)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 0, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "# ---------------- SAVE ----------------\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "out_path = \"outputs/result3.jpg\"\n",
    "cv2.imwrite(out_path, img)\n",
    "\n",
    "print(f\"Inference complete. Saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(\n",
    "    preds,\n",
    "    img_size=416,\n",
    "    num_classes=7,\n",
    "    obj_thresh=0.7,\n",
    "    score_thresh=0.6,\n",
    "    max_detections=5\n",
    "):\n",
    "    preds = preds.permute(0, 2, 3, 1)  # [B, S, S, 5+C]\n",
    "    B, S, _, _ = preds.shape\n",
    "\n",
    "    all_outputs = []\n",
    "\n",
    "    for b in range(B):\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        labels = []\n",
    "\n",
    "        for gy in range(S):\n",
    "            for gx in range(S):\n",
    "                obj = torch.sigmoid(preds[b, gy, gx, 4]).item()\n",
    "                if obj < obj_thresh:\n",
    "                    continue\n",
    "\n",
    "                cls_probs = torch.sigmoid(preds[b, gy, gx, 5:])\n",
    "                cls_id = torch.argmax(cls_probs).item()\n",
    "                cls_conf = cls_probs[cls_id].item()\n",
    "\n",
    "                score = obj * cls_conf\n",
    "                if score < score_thresh:\n",
    "                    continue\n",
    "\n",
    "                cx, cy, w, h = torch.sigmoid(\n",
    "                    preds[b, gy, gx, :4]\n",
    "                ).cpu().numpy()\n",
    "\n",
    "                # IMAGE-normalized decode (matches your dataset)\n",
    "                cx *= img_size\n",
    "                cy *= img_size\n",
    "                w  *= img_size\n",
    "                h  *= img_size\n",
    "\n",
    "                x1 = cx - w / 2\n",
    "                y1 = cy - h / 2\n",
    "                x2 = cx + w / 2\n",
    "                y2 = cy + h / 2\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                scores.append(score)\n",
    "                labels.append(cls_id)\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "            scores = torch.tensor(scores, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "            # -------- MAX DETECTIONS --------\n",
    "            scores_sorted, idx = scores.sort(descending=True)\n",
    "            idx = idx[:max_detections]\n",
    "\n",
    "            boxes = boxes[idx]\n",
    "            scores = scores_sorted[:max_detections]\n",
    "            labels = labels[idx]\n",
    "        else:\n",
    "            boxes = torch.zeros((0, 4))\n",
    "            scores = torch.zeros((0,))\n",
    "            labels = torch.zeros((0,), dtype=torch.long)\n",
    "\n",
    "        all_outputs.append({\n",
    "            \"boxes\": boxes,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels\n",
    "        })\n",
    "\n",
    "    return all_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(2.3653e-06), 'map_50': tensor(-1.), 'map_75': tensor(-1.), 'map_small': tensor(-1.), 'map_medium': tensor(-1.), 'map_large': tensor(2.3653e-06), 'mar_1': tensor(0.0022), 'mar_10': tensor(0.0028), 'mar_100': tensor(0.0028), 'mar_small': tensor(-1.), 'mar_medium': tensor(-1.), 'mar_large': tensor(0.0028), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.), 'classes': tensor([0, 1, 2, 3, 4, 5, 6], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader.data_load import UnderwaterDataset\n",
    "\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.25])\n",
    "\n",
    "val_dataset = UnderwaterDataset(\n",
    "    img_dir=\"/Users/anirudhmamgain/Desktop/Object_detection_from_scratch/Dataset/valid/images\",\n",
    "    label_dir=\"/Users/anirudhmamgain/Desktop/Object_detection_from_scratch/Dataset/valid/labels\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        preds = model(imgs)\n",
    "\n",
    "        outputs = decode_predictions(\n",
    "            preds,\n",
    "            img_size=416,\n",
    "            num_classes=7,\n",
    "            obj_thresh=0.05,\n",
    "            score_thresh=0.05,\n",
    "            max_detections=100\n",
    "        )\n",
    "\n",
    "        gt = []\n",
    "        for t in targets:\n",
    "            obj_mask = t[..., 4] == 1\n",
    "            if obj_mask.sum() == 0:\n",
    "                gt.append({\n",
    "                    \"boxes\": torch.zeros((0, 4)),\n",
    "                    \"labels\": torch.zeros((0,), dtype=torch.long)\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            cxcywh = t[..., 0:4][obj_mask].clone()\n",
    "            labels = torch.argmax(t[..., 5:], dim=-1)[obj_mask]\n",
    "\n",
    "            cx = cxcywh[:, 0] * 416\n",
    "            cy = cxcywh[:, 1] * 416\n",
    "            w  = cxcywh[:, 2] * 416\n",
    "            h  = cxcywh[:, 3] * 416\n",
    "\n",
    "            x1 = cx - w / 2\n",
    "            y1 = cy - h / 2\n",
    "            x2 = cx + w / 2\n",
    "            y2 = cy + h / 2\n",
    "\n",
    "            boxes = torch.stack([x1, y1, x2, y2], dim=1)\n",
    "\n",
    "            gt.append({\n",
    "                \"boxes\": boxes,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "        metric.update(outputs, gt)\n",
    "\n",
    "results = metric.compute()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 125.39\n",
      "Latency per image: 7.98 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "dummy = torch.randn(1, 3, 416, 416).to(device)\n",
    "\n",
    "for _ in range(20):\n",
    "    _ = model(dummy)\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    torch.mps.synchronize()\n",
    "\n",
    "start = time.time()\n",
    "num_runs = 100\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    _ = model(dummy)\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    torch.mps.synchronize()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "fps = num_runs / (end - start)\n",
    "latency = (end - start) / num_runs * 1000\n",
    "\n",
    "print(f\"FPS: {fps:.2f}\")\n",
    "print(f\"Latency per image: {latency:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 25.14\n",
      "Latency per image: 39.77 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "dummy = torch.randn(1, 3, 416, 416).to(device)\n",
    "\n",
    "for _ in range(20):\n",
    "    _ = model(dummy)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "num_runs = 100\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    _ = model(dummy)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "fps = num_runs / (end - start)\n",
    "latency = (end - start) / num_runs * 1000\n",
    "\n",
    "print(f\"FPS: {fps:.2f}\")\n",
    "print(f\"Latency per image: {latency:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 6.03 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "temp_path = \"temp_model.pth\"\n",
    "torch.save(model.state_dict(), temp_path)\n",
    "\n",
    "size_mb = os.path.getsize(temp_path) / (1024 * 1024)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")\n",
    "\n",
    "os.remove(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trade-off Results\n",
      "\n",
      "   Speed | mAP@0.25: 0.0001 | FPS: 125.60 | Avg Det/Image: 3.00\n",
      "Balanced | mAP@0.25: 0.0000 | FPS: 125.49 | Avg Det/Image: 5.00\n",
      "  Recall | mAP@0.25: 0.0000 | FPS: 122.90 | Avg Det/Image: 10.00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader.data_load import UnderwaterDataset\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "IMG_SIZE = 416\n",
    "NUM_CLASSES = 7\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "CONFIGS = {\n",
    "    \"Speed\": {\n",
    "        \"obj_thresh\": 0.85,\n",
    "        \"score_thresh\": 0.80,\n",
    "        \"nms_iou\": 0.30,\n",
    "        \"max_det\": 3\n",
    "    },\n",
    "    \"Balanced\": {\n",
    "        \"obj_thresh\": 0.70,\n",
    "        \"score_thresh\": 0.60,\n",
    "        \"nms_iou\": 0.50,\n",
    "        \"max_det\": 5\n",
    "    },\n",
    "    \"Recall\": {\n",
    "        \"obj_thresh\": 0.50,\n",
    "        \"score_thresh\": 0.50,\n",
    "        \"nms_iou\": 0.70,\n",
    "        \"max_det\": 10\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---------------- DATA ----------------\n",
    "val_dataset = UnderwaterDataset(\n",
    "    img_dir=\"Dataset/valid/images\",\n",
    "    label_dir=\"Dataset/valid/labels\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# ---------------- FPS MEASUREMENT ----------------\n",
    "def measure_fps():\n",
    "    dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy)\n",
    "\n",
    "    if DEVICE.type == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    runs = 100\n",
    "    for _ in range(runs):\n",
    "        _ = model(dummy)\n",
    "\n",
    "    if DEVICE.type == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "\n",
    "    return runs / (time.time() - start)\n",
    "\n",
    "# ---------------- MAIN LOOP ----------------\n",
    "results = []\n",
    "\n",
    "for name, cfg in CONFIGS.items():\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.25])\n",
    "    total_detections = 0\n",
    "    total_images = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            preds = model(imgs)\n",
    "\n",
    "            outputs = decode_predictions(\n",
    "                preds,\n",
    "                img_size=IMG_SIZE,\n",
    "                num_classes=NUM_CLASSES,\n",
    "                obj_thresh=cfg[\"obj_thresh\"],\n",
    "                score_thresh=cfg[\"score_thresh\"],\n",
    "                max_detections=cfg[\"max_det\"]\n",
    "            )\n",
    "\n",
    "            gt = []\n",
    "            for t in targets:\n",
    "                obj_mask = t[..., 4] == 1\n",
    "                if obj_mask.sum() == 0:\n",
    "                    gt.append({\n",
    "                        \"boxes\": torch.zeros((0, 4)),\n",
    "                        \"labels\": torch.zeros((0,), dtype=torch.long)\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                cxcywh = t[..., 0:4][obj_mask]\n",
    "                labels = torch.argmax(t[..., 5:], dim=-1)[obj_mask]\n",
    "\n",
    "                cx = cxcywh[:, 0] * IMG_SIZE\n",
    "                cy = cxcywh[:, 1] * IMG_SIZE\n",
    "                w  = cxcywh[:, 2] * IMG_SIZE\n",
    "                h  = cxcywh[:, 3] * IMG_SIZE\n",
    "\n",
    "                boxes = torch.stack([\n",
    "                    cx - w / 2,\n",
    "                    cy - h / 2,\n",
    "                    cx + w / 2,\n",
    "                    cy + h / 2\n",
    "                ], dim=1)\n",
    "\n",
    "                gt.append({\"boxes\": boxes, \"labels\": labels})\n",
    "\n",
    "            metric.update(outputs, gt)\n",
    "\n",
    "            for o in outputs:\n",
    "                total_detections += o[\"boxes\"].shape[0]\n",
    "                total_images += 1\n",
    "\n",
    "    metrics = metric.compute()\n",
    "    fps = measure_fps()\n",
    "\n",
    "    results.append({\n",
    "        \"Config\": name,\n",
    "        \"mAP@0.25\": metrics[\"map\"].item(),\n",
    "        \"FPS\": fps,\n",
    "        \"Avg Detections\": total_detections / total_images\n",
    "    })\n",
    "\n",
    "# ---------------- PRINT RESULTS ----------------\n",
    "print(\"\\nTrade-off Results\\n\")\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['Config']:>8} | \"\n",
    "        f\"mAP@0.25: {r['mAP@0.25']:.4f} | \"\n",
    "        f\"FPS: {r['FPS']:.2f} | \"\n",
    "        f\"Avg Det/Image: {r['Avg Detections']:.2f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
